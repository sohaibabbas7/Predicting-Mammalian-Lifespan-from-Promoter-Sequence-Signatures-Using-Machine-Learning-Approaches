# -*- coding: utf-8 -*-
"""Untitled16.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IdHKfbP-7vV-RqZQ4UHYRwGBxdmDzpVy

# **Promoter-Only Mammalian Longevity Pipeline**
End-to-end, reproducible pipeline for predicting **species-level maximum lifespan** from **1-kb promoter** sequences.

**Contents**
0) Setup & pinned dependencies  
1) Ingestion, schema & PII checks *(demo mode if data absent)*  
2) EDA (distributions, counts, GC/CpG)  
3) Feature engineering (CpG O:E, GC%, 4-mers) → species matrix  
4) Baselines (Ridge, Gradient Boosting) + CV  
5) MIL deep model (CNN encoder + mean/attention pooling)  
6) Evaluation with bootstrap CIs + Acceptance gate  
7) Robustness & ablations (bag size, pooling; CpG vs k-mers)  
8) Publication-grade plots & tables (export to `/reports`)  
9) Run manifest (JSON) & tiny smoke test
"""

# ╔══════════════════════════════════════════════════════════════════════╗
# ║ 0) Setup & Environment — Colab-safe (no NumPy/Torch downgrades)      ║
# ╚══════════════════════════════════════════════════════════════════════╝
import os, sys, math, json, random, subprocess, re, time, hashlib, textwrap
from datetime import datetime
from pathlib import Path

IN_COLAB = "google.colab" in sys.modules
if IN_COLAB:
    # Pin only safe minimums that don't fight Colab's NumPy/Torch
    !pip -q install --upgrade --no-input --quiet \
        pandas>=2.2.2 scikit-learn>=1.6.1 scipy>=1.11 \
        tqdm>=4.67 rich>=13.7.1 xgboost>=2.0.3 \
        biopython>=1.83 matplotlib>=3.8 seaborn>=0.13.2

# (Optional) Mount Drive if you keep data there
try:
    from google.colab import drive  # type: ignore
    if not os.path.ismount("/content/drive"):
        drive.mount('/content/drive')
except Exception:
    pass

from rich.console import Console
console = Console()

import numpy as np, pandas as pd
from tqdm import tqdm
import matplotlib.pyplot as plt
import seaborn as sns
import sklearn
from IPython.display import display
import torch, torch.nn as nn, torch.nn.functional as F

# Guard against NumPy ABI issues
try:
    from packaging.version import Version
    if IN_COLAB and Version(np.__version__).major < 2:
        console.print(f"[yellow]NumPy {np.__version__} detected; upgrading to >=2.0.")
        !pip -q install --upgrade "numpy>=2.0,<3"
        raise SystemExit("NumPy upgraded. Restart runtime (Runtime ▶ Restart) and rerun this cell.")
except Exception:
    pass

def seed_everything(seed: int = 42):
    random.seed(seed); np.random.seed(seed)
    torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True; torch.backends.cudnn.benchmark = False

CFG = dict(
    rng_seed=42,
    data_dir="/content/data",
    reports_dir="/content/reports",
    artifacts_dir="/content/artifacts",
    use_gpu=torch.cuda.is_available(),
    kmer_k=4,
    bag_size=256,
    epochs=15,
    batch_size=1,
    lr=5e-4,
    patience=4,
    atten_dim=64,
    conv_filters=64,
    conv_kernel=9,
    val_split=0.15,
    test_split=0.15,
    n_boot=1000,
    demo_species=30,
    demo_promoters=400
)

seed_everything(CFG["rng_seed"])

DATA_DIR = Path(CFG["data_dir"]); DATA_DIR.mkdir(parents=True, exist_ok=True)
REPORTS  = Path(CFG["reports_dir"]); REPORTS.mkdir(parents=True, exist_ok=True)
ARTIFACTS= Path(CFG["artifacts_dir"]); ARTIFACTS.mkdir(parents=True, exist_ok=True)

try:
    (ARTIFACTS/"requirements.txt").write_text(subprocess.check_output(["pip","freeze"]).decode())
except Exception as e:
    console.print(f"[yellow]Could not write requirements.txt: {e}")

run_id = f"run_{int(time.time())}"
console.rule(f"[bold green]Env | numpy {np.__version__} | pandas {pd.__version__} | sklearn {sklearn.__version__} | torch {torch.__version__}")

# ╔══════════════════════════════════════════════════════════════════════╗
# ║ 1) Helpers for metrics (sklearn/scipy version-safe)                  ║
# ╚══════════════════════════════════════════════════════════════════════╝
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from scipy.stats import spearmanr

def safe_rmse(y_true, y_pred):
    try:
        return mean_squared_error(y_true, y_pred, squared=False)
    except TypeError:
        return float(np.sqrt(mean_squared_error(y_true, y_pred)))

def spearman_stat(y_true, y_pred):
    r = spearmanr(y_true, y_pred)
    if hasattr(r, "statistic"):   return float(r.statistic)
    if hasattr(r, "correlation"): return float(r.correlation)
    try: return float(r[0])
    except Exception: return float(np.nan)

def metric_bootstrap(y_true, y_pred, reps=1000, seed=42):
    rng = np.random.default_rng(seed)
    yt = np.asarray(y_true); yp = np.asarray(y_pred); n = len(yt)
    maes, rmses, r2s, rhos = [], [], [], []
    for _ in range(reps):
        idx = rng.integers(0, n, size=n)
        yti, ypi = yt[idx], yp[idx]
        maes.append(mean_absolute_error(yti, ypi))
        try: rmses.append(mean_squared_error(yti, ypi, squared=False))
        except TypeError: rmses.append(np.sqrt(mean_squared_error(yti, ypi)))
        r2s.append(r2_score(yti, ypi))
        rhos.append(spearman_stat(yti, ypi))
    def ci(a): lo,hi = np.percentile(a,[2.5,97.5]); return float(lo), float(hi)
    return {
        "MAE_CI": ci(maes),
        "RMSE_CI": ci(rmses),
        "R2_CI": ci(r2s),
        "rho_CI": ci(rhos),
    }

"""## 1) Ingestion, schema checks & PII scan

**Expected inputs:**
- Promoters (one-hot): `/content/data/promoters/all_promoters.npy` — shape **[N, 4, 1000]**
- Promoter index: `/content/data/promoters/promoter_index.tsv` — columns: `row_start, row_end, species, assembly`
- Labels: `/content/data/labels.csv` — columns: `species,lifespan_years`
- *(optional)* Taxonomy: `/content/data/taxonomy.csv` — columns: `species,order,family`

"""

# ╔══════════════════════════════════════════════════════════════════════╗
# ║ 1. Ingestion, schema checks & PII scan (Drive-aware, robust)        ║
# ╚══════════════════════════════════════════════════════════════════════╝
from pathlib import Path
import re

# Auto-mount Drive (safe no-op outside Colab)
try:
    if IN_COLAB:
        from google.colab import drive  # type: ignore
        if not os.path.ismount("/content/drive"):
            drive.mount("/content/drive")
except Exception:
    pass

# --- Locate data (local defaults + your Drive folder) -------------------
PROM_DIR = DATA_DIR / "promoters"
PROM_DIR.mkdir(parents=True, exist_ok=True)

DRIVE_ROOT = Path("/content/drive/MyDrive") if IN_COLAB else Path(".")
GT_PROM_DIR = DRIVE_ROOT / "GenomeThesis" / "promoters"  # your Drive path

# Candidates for each required input
NPY_CANDIDATES = [
    PROM_DIR / "all_promoters.npy",
    GT_PROM_DIR / "all_species_promoters.npy",  # preferred (Drive)
]
IDX_CANDIDATES = [
    PROM_DIR / "promoter_index.tsv",
    GT_PROM_DIR / "promoter_index.tsv",         # preferred (Drive)
]
LBL_CANDIDATES = [
    DATA_DIR / "labels.csv",
    DATA_DIR / "labels.npy",
    GT_PROM_DIR / "all_species_labels.npy",     # preferred (Drive, can be 1-D vector)
]
TAX_CANDIDATES = [
    DATA_DIR / "taxonomy.csv",
    GT_PROM_DIR / "taxonomy.csv",               # optional
]

def first_existing(paths):
    for p in paths:
        if p and Path(p).exists():
            return Path(p)
    return None

NPY_PATH = first_existing(NPY_CANDIDATES)
IDX_TSV  = first_existing(IDX_CANDIDATES)
LBL_PATH = first_existing(LBL_CANDIDATES)
TAX_PATH = first_existing(TAX_CANDIDATES)

# --- Basic PII scan (emails/phone-like) for CSV text fields ------------
def pii_scan_text(s: str) -> bool:
    patterns = [
        r"[A-Za-z0-9\._%+-]+@[A-Za-z0-9\.-]+\.[A-Za-z]{2,}",
        r"\b\d{3}[-.\s]?\d{3}[-.\s]?\d{4}\b"
    ]
    try:
        return any(re.search(p, s) for p in patterns)
    except Exception:
        return False

# --- Robust labels loader ----------------------------------------------
def load_labels_any_robust(path: Path, meta: pd.DataFrame, n_promoters: int) -> pd.DataFrame:
    """
    Returns DataFrame with: species (str), lifespan_years (float).
    Supports:
      • CSV with species + lifespan column
      • NPY numeric 1-D vector:
          - len == n_species   → per-species vector (mapped in meta order)
          - len == n_promoters → per-promoter vector (aggregated by species median)
      • NPY 0-d pickled dict/DataFrame/Series/list/tuple
      • NPY structured array with 'species' and lifespan field
      • NPY 2-D array with [species, lifespan]
    """
    def finalize(df: pd.DataFrame) -> pd.DataFrame:
        if "species" not in df.columns or "lifespan_years" not in df.columns:
            raise ValueError("labels: expected columns ['species','lifespan_years'] after normalization.")
        df["species"] = df["species"].astype(str).str.strip()
        df["lifespan_years"] = pd.to_numeric(df["lifespan_years"], errors="coerce")
        return df.dropna(subset=["lifespan_years"]).drop_duplicates(subset=["species"])

    # CSV
    if path.suffix.lower() == ".csv":
        df = pd.read_csv(path)
        cols = {c.lower(): c for c in df.columns}
        sp_key   = cols.get("species") or cols.get("species_name") or cols.get("taxon") or cols.get("name")
        life_key = next((cols[k] for k in ("lifespan_years","lifespan","max_lifespan","maximum_lifespan","mlsp") if k in cols), None)
        if not sp_key or not life_key:
            raise ValueError(f"labels.csv must include species and lifespan-like columns. Found: {list(df.columns)}")
        return finalize(df.rename(columns={sp_key:"species", life_key:"lifespan_years"})[["species","lifespan_years"]])

    # NPY
    if path.suffix.lower() != ".npy":
        raise ValueError(f"Unsupported labels file type: {path.suffix}")

    arr = np.load(path, allow_pickle=True)
    n_species = meta["species"].nunique()

    # 1-D numeric vector (most likely your case)
    if isinstance(arr, np.ndarray) and arr.ndim == 1 and np.issubdtype(arr.dtype, np.number):
        if len(arr) == n_species:
            sp_order = meta.drop_duplicates("species", keep="first")["species"].tolist()
            console.print(f"[green]Detected per-species labels vector: {len(arr)} values for {n_species} species.")
            return finalize(pd.DataFrame({"species": sp_order, "lifespan_years": arr}))
        if len(arr) == n_promoters:
            rows, stds = [], []
            for _, r in meta.iterrows():
                sl = slice(int(r.row_start), int(r.row_end))
                vals = arr[sl].astype(float)
                rows.append((r.species, float(np.nanmedian(vals))))
                stds.append(float(np.nanstd(vals)))
            console.print(f"[green]Aggregated per-promoter labels → per-species (median). "
                          f"Max within-species std = {np.nanmax(stds):.4f}")
            return finalize(pd.DataFrame(rows, columns=["species","lifespan_years"]))
        raise ValueError(f"Numeric labels length {len(arr)} does not match n_species {n_species} "
                         f"or n_promoters {n_promoters}.")

    # 0-dim pickled object (dict/DataFrame/Series/list/tuple)
    if isinstance(arr, np.ndarray) and arr.shape == ():
        obj = arr.item()
        if isinstance(obj, pd.DataFrame):
            df = obj.copy()
            lc = {c.lower(): c for c in df.columns}
            if "species" not in lc:
                for alt in ("species_name","taxon","name"):
                    if alt in lc: df = df.rename(columns={lc[alt]:"species"})
            for lk in ("lifespan_years","lifespan","max_lifespan","maximum_lifespan","mlsp"):
                if lk in lc: df = df.rename(columns={lc[lk]:"lifespan_years"})
            return finalize(df)
        if isinstance(obj, pd.Series):
            df = obj.rename("lifespan_years").reset_index().rename(columns={"index":"species"})
            return finalize(df)
        if isinstance(obj, dict):
            if "species" in obj:
                life_key = next((k for k in ("lifespan_years","lifespan","max_lifespan","maximum_lifespan","mlsp") if k in obj), None)
                if life_key is None:
                    raise ValueError("labels dict missing lifespan key.")
                return finalize(pd.DataFrame({"species": obj["species"], "lifespan_years": obj[life_key]}))
            ser = pd.Series(obj)
            return finalize(pd.DataFrame({"species": ser.index, "lifespan_years": ser.values}))
        if isinstance(obj, (list, tuple)):
            if len(obj) == 2 and all(isinstance(x, (list, tuple, np.ndarray, pd.Series)) for x in obj):
                return finalize(pd.DataFrame({"species": list(map(str, obj[0])), "lifespan_years": obj[1]}))
            if len(obj) and isinstance(obj[0], (list, tuple)) and len(obj[0]) >= 2:
                return finalize(pd.DataFrame({"species": [str(t[0]) for t in obj], "lifespan_years": [t[1] for t in obj]}))
        raise ValueError("labels.npy (object) unsupported type; expect dict/DataFrame/Series/list-of-tuples.")

    # Structured array with named fields
    if getattr(arr, "dtype", None) is not None and getattr(arr.dtype, "names", None):
        names = [n.lower() for n in arr.dtype.names]
        s = arr.dtype.names[names.index("species")]
        l = arr.dtype.names[names.index("lifespan_years")] if "lifespan_years" in names else arr.dtype.names[names.index("lifespan")]
        return finalize(pd.DataFrame({"species": arr[s].astype(str), "lifespan_years": arr[l]}))

    # 2-D [species, lifespan]
    if isinstance(arr, np.ndarray) and arr.ndim == 2 and arr.shape[1] >= 2:
        return finalize(pd.DataFrame({"species": arr[:,0].astype(str), "lifespan_years": arr[:,1]}))

    raise ValueError("Unrecognized labels.npy format.")

# --- Ingest function ----------------------------------------------------
def ingest():
    demo = not (NPY_PATH and IDX_TSV and LBL_PATH)
    if demo:
        console.print("[yellow]Data not found → entering DEMO MODE (synthetic data).")
        S, P, L = CFG["demo_species"], CFG["demo_promoters"], 1000
        X = np.zeros((S*P, 4, L), dtype=np.float32)
        species, lifespans = [], []
        rng = np.random.default_rng(CFG["rng_seed"])
        cpg_bias = rng.uniform(0, 1, size=S)  # weak synthetic signal
        for si in range(S):
            for pi in range(P):
                idx = si*P + pi
                seq = rng.integers(0, 4, size=L)
                for j in range(0, L-1):
                    if rng.random() < 0.02 * cpg_bias[si]:
                        seq[j] = 1; seq[j+1] = 2  # C then G
                X[idx, seq, np.arange(L)] = 1.0
                species.append(f"sp_{si:03d}")
            lifespans.append(10 + 20*cpg_bias[si] + rng.normal(0, 3))
        meta = pd.DataFrame({
            "row_start": np.arange(0, S*P, P),
            "row_end":   np.arange(P, (S+1)*P, P),
            "species":   [f"sp_{i:03d}" for i in range(S)],
            "assembly":  [f"asm_{i:03d}" for i in range(S)]
        })
        labels = pd.DataFrame({"species": meta["species"], "lifespan_years": lifespans})
        taxonomy = None
        used_paths = {}
        return X, meta, labels, taxonomy, "demo", used_paths

    # --- Real data path prints
    console.print(f"[green]Using promoters: {NPY_PATH}")
    console.print(f"[green]Using index:     {IDX_TSV}")
    console.print(f"[green]Using labels:   {LBL_PATH}")

    # Load promoters and index
    X = np.load(NPY_PATH, mmap_mode="r")
    meta = pd.read_csv(IDX_TSV, sep="\t")

    # Normalize meta columns (case-insensitive + synonyms)
    meta_cols = {c.lower(): c for c in meta.columns}
    rename_map = {}
    for want, cands in {
        "row_start": ("row_start","start_row","rowstart","start_idx","start"),
        "row_end":   ("row_end","end_row","rowend","end_idx","end"),
        "species":   ("species","species_name","taxon","name","sp"),
        "assembly":  ("assembly","assembly_accession","asm","accession"),
    }.items():
        for cand in cands:
            if cand in meta_cols:
                rename_map[meta_cols[cand]] = want
                break
    meta = meta.rename(columns=rename_map)

    # If species missing but assembly exists, synthesize species from assembly (ensure unique)
    if "species" not in meta.columns and "assembly" in meta.columns:
        sp = meta["assembly"].astype(str).str.strip()
        dup_idx = sp.groupby(sp).cumcount()
        meta["species"] = np.where(dup_idx == 0, sp, sp + "_" + (dup_idx + 1).astype(str))

    # Validate required columns
    missing_row_cols = [k for k in ("row_start","row_end") if k not in meta.columns]
    if missing_row_cols:
        raise ValueError(f"promoter_index.tsv is missing required columns: {missing_row_cols}. "
                         f"Found columns: {list(meta.columns)}")
    if "species" not in meta.columns:
        raise ValueError("promoter_index.tsv must include (or allow deriving) a 'species' column (had neither 'species' nor usable 'assembly').")

    # Enforce dtypes and clean strings
    meta["row_start"] = pd.to_numeric(meta["row_start"], errors="raise").astype(int)
    meta["row_end"]   = pd.to_numeric(meta["row_end"],   errors="raise").astype(int)
    meta["species"]   = meta["species"].astype(str).str.strip()
    if "assembly" in meta.columns:
        meta["assembly"] = meta["assembly"].astype(str).str.strip()
    else:
        meta["assembly"] = "NA"

    # Sanity checks on index vs promoters
    n_promoters = len(X)
    if meta["row_start"].min() < 0 or meta["row_end"].max() > n_promoters:
        raise ValueError(f"Index rows outside promoter array bounds: [0,{n_promoters})")
    if not (meta["row_end"] > meta["row_start"]).all():
        bad = meta.loc[~(meta["row_end"] > meta["row_start"])].head()
        raise ValueError(f"Found row_end <= row_start for some species (e.g., {bad.to_dict('records')[:3]})")

    # Load labels (robust)
    labels = load_labels_any_robust(LBL_PATH, meta=meta, n_promoters=n_promoters)
    console.print(f"[green]Labels loaded: {len(labels)} rows | columns = {list(labels.columns)}")
    display(labels.head())

    # Optional taxonomy
    taxonomy = None
    if TAX_PATH and TAX_PATH.exists():
        console.print(f"[green]Using taxonomy: {TAX_PATH}")
        taxonomy = pd.read_csv(TAX_PATH)
    else:
        console.print("[yellow]No taxonomy found → MIL clade-aware grouping will be disabled.")

    # PII scan on text columns
    for df, name in [(labels,"labels"), (taxonomy,"taxonomy")]:
        if df is None: continue
        for col in df.columns:
            if pd.api.types.is_string_dtype(df[col]):
                if df[col].astype(str).map(pii_scan_text).any():
                    raise RuntimeError(f"PII-like token detected in {name} column: {col}")

    used_paths = {"promoters": str(NPY_PATH), "index": str(IDX_TSV), "labels": str(LBL_PATH)}
    if taxonomy is not None:
        used_paths["taxonomy"] = str(TAX_PATH)
    return X, meta, labels, taxonomy, "real", used_paths

# ---- Run ingestion -----------------------------------------------------
X, meta, labels, taxonomy, MODE, USED = ingest()
console.print(f"[bold]Mode:[/bold] {MODE} | promoters={len(X):,} | species={meta['species'].nunique():,}")
assert X.shape[1:] == (4, 1000), f"Promoters must be one-hot with shape [N,4,1000], got {X.shape}"

# Merge meta with labels (species-level)
species_lifespan = labels.set_index("species")["lifespan_years"].to_dict()
meta["lifespan_years"] = meta["species"].map(species_lifespan)
missing = meta["lifespan_years"].isna().sum()
if missing:
    missing_sp = meta.loc[meta["lifespan_years"].isna(), "species"].unique().tolist()
    raise ValueError(f"Missing lifespan labels for {missing} species, e.g., {missing_sp[:5]}")

if MODE == "real":
    console.print("[blue]Files in use:", USED)

"""## 2) EDA — distributions and sanity checks"""

# ╔══════════════════════════════════════════════════════════════════════╗
# ║ 3) EDA — distributions and sanity checks                             ║
# ╚══════════════════════════════════════════════════════════════════════╝
sns.set_context("talk")
fig, axes = plt.subplots(1,3, figsize=(18,5))
# Lifespan
axes[0].hist(meta["lifespan_years"], bins=15, edgecolor="black")
axes[0].set_title("Species lifespan (years)")
axes[0].set_xlabel("years"); axes[0].set_ylabel("count")
# Promoters per species
axes[1].hist(meta["row_end"]-meta["row_start"], bins=15, edgecolor="black")
axes[1].set_title("Promoters per species"); axes[1].set_xlabel("promoters")
# Quick GC estimate subset
idx = np.random.choice(len(X), size=min(2000, len(X)), replace=False)
gc = (X[idx,1].sum(1)+X[idx,2].sum(1))/1000.0
axes[2].hist(gc, bins=15, edgecolor="black")
axes[2].set_title("GC% (subset)"); axes[2].set_xlabel("fraction")
plt.tight_layout()
plt.savefig(REPORTS/"eda_overview.png", dpi=200); plt.show()

"""## 3) Feature engineering — CpG/GC and 4-mers → species matrix"""

# ╔══════════════════════════════════════════════════════════════════════╗
# ║ 4) Feature engineering — CpG/GC and 4-mers → species matrix          ║
# ╚══════════════════════════════════════════════════════════════════════╝
import itertools
from collections import Counter
BASES="ACGT"; K=CFG["kmer_k"]
KMERS=["".join(p) for p in itertools.product(BASES, repeat=K)]

def promoter_features(one_hot: np.ndarray) -> np.ndarray:
    L = one_hot.shape[1]; a,c,g,t = one_hot.sum(1); gc=(g+c)/L
    cpg_obs = (one_hot[1] * np.roll(one_hot[2], -1)).sum()
    cpg_exp = (c/L)*(g/L)*L if L else 1
    cpg_oe = float(cpg_obs / cpg_exp) if cpg_exp else 0.0
    seq = "".join(BASES[i] for i in one_hot.argmax(0))
    km = Counter(seq[i:i+K] for i in range(L-K+1))
    kvec = np.array([km.get(k,0)/(L-K+1) for k in KMERS], dtype=np.float32)
    return np.concatenate(([gc, cpg_oe], kvec)).astype(np.float32)

CACHE = DATA_DIR / f"prom_feature_cache_k{K}.memmap"
F_DIM = 2 + (4**K)

def build_or_load_cache():
    if CACHE.exists():
        try:
            return np.memmap(CACHE, mode="r", dtype=np.float32, shape=(len(X), F_DIM))
        except Exception:
            CACHE.unlink(missing_ok=True)
    fmat = np.memmap(CACHE, mode="w+", dtype=np.float32, shape=(len(X), F_DIM))
    for i in tqdm(range(len(X)), desc="feature-cache"):
        fmat[i] = promoter_features(X[i])
    del fmat
    return np.memmap(CACHE, mode="r", dtype=np.float32, shape=(len(X), F_DIM))

fmat = build_or_load_cache()

def species_feature_matrix(meta: pd.DataFrame, fmat: np.memmap):
    rows=[]
    for _, r in meta.iterrows():
        sl = slice(int(r.row_start), int(r.row_end))
        agg = fmat[sl].mean(0)
        rows.append((r["species"], *agg, r["lifespan_years"]))
    cols=["species","gc","cpg_oe"]+[f"kmer_{k}" for k in KMERS]+["lifespan_years"]
    return pd.DataFrame(rows, columns=cols)

species_df = species_feature_matrix(meta, fmat)
species_df.to_csv(DATA_DIR/"species_matrix.csv", index=False)
console.print("[green]Species feature matrix saved:", DATA_DIR/"species_matrix.csv")
display(species_df.head())

"""## 4) Baselines — Ridge & Gradient Boosting with species-level CV

"""

# ╔══════════════════════════════════════════════════════════════════════╗
# ║ 5) Baselines — Ridge & GBR with species-level CV                     ║
# ╚══════════════════════════════════════════════════════════════════════╝
import matplotlib.pyplot as plt
from sklearn.model_selection import KFold, GroupKFold
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import Ridge
from sklearn.ensemble import GradientBoostingRegressor

Y = species_df["lifespan_years"].values.astype(float)
Xtab = species_df.drop(columns=["species","lifespan_years"])

# Optional clade-aware grouping
groups = None
tax_path = DATA_DIR/"taxonomy.csv"
if tax_path.exists():
    tax = pd.read_csv(tax_path)
    fam = tax["family"] if "family" in tax.columns else pd.Series(index=tax.index, dtype=object)
    ord_ = tax["order"]  if "order"  in tax.columns else pd.Series(index=tax.index, dtype=object)
    fam_or_order = fam.fillna(ord_)
    gmap = dict(zip(tax["species"].astype(str), fam_or_order.astype(str)))
    groups = species_df["species"].astype(str).map(gmap).fillna(species_df["species"]).values

cv = GroupKFold(n_splits=5) if groups is not None else KFold(n_splits=5, shuffle=True, random_state=CFG["rng_seed"])

def evaluate_model(model, name):
    maes, rmses, r2s, rhos = [], [], [], []
    preds_all, trues_all = [], []
    for tr, te in cv.split(Xtab, Y, groups=groups):
        pipe = Pipeline([("scaler", StandardScaler()), ("reg", model)])
        pipe.fit(Xtab.iloc[tr], Y[tr])
        p = pipe.predict(Xtab.iloc[te]); t = Y[te]
        preds_all.extend(p); trues_all.extend(t)
        maes.append(mean_absolute_error(t,p))
        rmses.append(safe_rmse(t,p))
        r2s.append(r2_score(t,p))
        rhos.append(spearman_stat(t,p))
    res = dict(model=name, MAE=float(np.mean(maes)), RMSE=float(np.mean(rmses)),
               R2=float(np.mean(r2s)), rho=float(np.mean(rhos)),
               n=len(Y), grouped_cv=bool(groups is not None))
    return res, np.array(trues_all), np.array(preds_all)

baseline_mean = float(np.mean(Y))
naive_mae = float(np.mean(np.abs(Y - baseline_mean)))
ridge_res, t_ridge, p_ridge = evaluate_model(Ridge(alpha=1.0), "Ridge")
gbr_res,   t_gbr,   p_gbr   = evaluate_model(GradientBoostingRegressor(random_state=CFG["rng_seed"]), "GBR")

baseline_table = pd.DataFrame([
    {"model":"NaiveMean","MAE":naive_mae,"RMSE":float(np.std(Y)), "R2":0.0,"rho":0.0,"n":len(Y),"grouped_cv":bool(groups is not None)},
    ridge_res, gbr_res
])
display(baseline_table)

plt.figure(figsize=(6,6))
plt.scatter(t_ridge, p_ridge, alpha=0.6, label="Ridge")
plt.scatter(t_gbr,   p_gbr,   alpha=0.6, label="GBR")
mn, mx = min(Y.min(), p_ridge.min(), p_gbr.min()), max(Y.max(), p_ridge.max(), p_gbr.max())
plt.plot([mn,mx],[mn,mx],'k--',lw=1)
plt.xlabel("True lifespan (years)"); plt.ylabel("Predicted")
plt.title("Baselines — Pred vs True")
plt.legend(); plt.tight_layout()
plt.savefig(REPORTS/"baselines_pred_vs_true.png", dpi=200); plt.show()

"""## 5) MIL deep model — CNN encoder + mean/attention pooling

"""

# ╔══════════════════════════════════════════════════════════════════════╗
# ║ 4. Baselines — Ridge & Gradient Boosting with species-level CV       ║
# ╚══════════════════════════════════════════════════════════════════════╝
import numpy as np, pandas as pd, matplotlib.pyplot as plt
from IPython.display import display
from sklearn.model_selection import KFold, GroupKFold
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import Ridge
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from scipy.stats import spearmanr

# --- helpers for older sklearn/scipy versions ---
def safe_rmse(y_true, y_pred):
    """Compute RMSE; compatible with sklearn versions without 'squared' kw."""
    try:
        return mean_squared_error(y_true, y_pred, squared=False)
    except TypeError:
        return float(np.sqrt(mean_squared_error(y_true, y_pred)))

def spearman_stat(y_true, y_pred):
    """Spearman ρ; works for SciPy returning tuple or SignificanceResult."""
    r = spearmanr(y_true, y_pred)
    # Newer SciPy returns an object with .statistic; older returns tuple
    if hasattr(r, "statistic"):
        return float(r.statistic)
    if hasattr(r, "correlation"):
        return float(r.correlation)
    # fallback to tuple
    try:
        return float(r[0])
    except Exception:
        return float(np.nan)

# Targets and features
Y = species_df["lifespan_years"].values.astype(float)
Xtab = species_df.drop(columns=["species","lifespan_years"])

# Optional clade-aware grouping if taxonomy exists
groups = None
tax_path = DATA_DIR / "taxonomy.csv"
if tax_path.exists():
    tax = pd.read_csv(tax_path)
    family = tax["family"] if "family" in tax.columns else pd.Series(index=tax.index, dtype=object)
    order  = tax["order"]  if "order"  in tax.columns else pd.Series(index=tax.index, dtype=object)
    fam_or_order = family.fillna(order)
    gmap = dict(zip(tax["species"].astype(str), fam_or_order.astype(str)))
    groups = species_df["species"].astype(str).map(gmap).fillna(species_df["species"]).values

# Cross-validation splitter
cv = GroupKFold(n_splits=5) if groups is not None else KFold(n_splits=5, shuffle=True, random_state=CFG["rng_seed"])

def evaluate_model(model, name):
    maes, rmses, r2s, rhos = [], [], [], []
    preds_all, trues_all = [], []
    for fold, (tr, te) in enumerate(cv.split(Xtab, Y, groups=groups)):
        pipe = Pipeline([("scaler", StandardScaler()), ("reg", model)])
        pipe.fit(Xtab.iloc[tr], Y[tr])
        p = pipe.predict(Xtab.iloc[te]); t = Y[te]
        preds_all.extend(p); trues_all.extend(t)
        maes.append(mean_absolute_error(t, p))
        rmses.append(safe_rmse(t, p))
        r2s.append(r2_score(t, p))
        rhos.append(spearman_stat(t, p))
    res = dict(
        model=name,
        MAE=float(np.mean(maes)),
        RMSE=float(np.mean(rmses)),
        R2=float(np.mean(r2s)),
        rho=float(np.mean(rhos)),
        n=len(Y),
        grouped_cv=bool(groups is not None)
    )
    return res, np.array(trues_all), np.array(preds_all)

# Naive mean baseline (for context)
baseline_mean = float(np.mean(Y))
naive_mae = float(np.mean(np.abs(Y - baseline_mean)))

# NOTE: Don't pass random_state to Ridge (not supported in some sklearn builds)
ridge_res, t_ridge, p_ridge = evaluate_model(Ridge(alpha=1.0), "Ridge")
gbr_res,   t_gbr,   p_gbr   = evaluate_model(GradientBoostingRegressor(random_state=CFG["rng_seed"]), "GBR")

baseline_table = pd.DataFrame([
    {"model":"NaiveMean","MAE":naive_mae,"RMSE":float(np.std(Y)), "R2":0.0,"rho":0.0, "n":len(Y), "grouped_cv":bool(groups is not None)},
    ridge_res, gbr_res
])
display(baseline_table)

# Save baseline plot
plt.figure(figsize=(6,6))
plt.scatter(t_ridge, p_ridge, alpha=0.6, label="Ridge")
plt.scatter(t_gbr,   p_gbr,   alpha=0.6, label="GBR")
mn, mx = min(Y.min(), p_ridge.min(), p_gbr.min()), max(Y.max(), p_ridge.max(), p_gbr.max())
plt.plot([mn, mx], [mn, mx], 'k--', lw=1)
plt.xlabel("True lifespan (years)"); plt.ylabel("Predicted")
plt.title("Baselines — Pred vs True")
plt.legend(); plt.tight_layout()
plt.savefig(REPORTS/"baselines_pred_vs_true.png", dpi=200); plt.show()

"""## 6) Evaluation with bootstrap CIs + Acceptance gate"""

# ╔══════════════════════════════════════════════════════════════════════╗
# ║ 6) Baseline ablations — feature subsets                              ║
# ╚══════════════════════════════════════════════════════════════════════╝
import numpy as np, pandas as pd
from sklearn.model_selection import KFold, GroupKFold
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import Ridge

# Build optional clade groups if taxonomy exists (aligns to species_df rows)
groups = None
tax_path = DATA_DIR / "taxonomy.csv"
if tax_path.exists():
    tax = pd.read_csv(tax_path)
    fam = tax["family"] if "family" in tax.columns else pd.Series(index=tax.index, dtype=object)
    ord_ = tax["order"]  if "order"  in tax.columns else pd.Series(index=tax.index, dtype=object)
    fam_or_order = fam.fillna(ord_)
    gmap = dict(zip(tax["species"].astype(str), fam_or_order.astype(str)))
    groups = species_df["species"].astype(str).map(gmap).fillna(species_df["species"]).values

def evaluate_model_X(Xframe, Yvec, model, name, groups=None, seed=CFG["rng_seed"]):
    cv = GroupKFold(n_splits=5) if groups is not None else KFold(n_splits=5, shuffle=True, random_state=seed)
    maes, rmses, r2s, rhos = [], [], [], []
    for tr, te in cv.split(Xframe, Yvec, groups=groups):
        pipe = Pipeline([("scaler", StandardScaler()), ("reg", model)])
        pipe.fit(Xframe.iloc[tr], Yvec[tr])
        p = pipe.predict(Xframe.iloc[te]); t = Yvec[te]
        maes.append(mean_absolute_error(t, p))
        try:
            rmse = mean_squared_error(t, p, squared=False)
        except TypeError:
            rmse = float(np.sqrt(mean_squared_error(t, p)))
        rmses.append(rmse)
        r2s.append(r2_score(t, p))
        rhos.append(spearman_stat(t, p))  # uses the helper defined earlier
    return dict(model=name,
                MAE=float(np.mean(maes)),
                RMSE=float(np.mean(rmses)),
                R2=float(np.mean(r2s)),
                rho=float(np.mean(rhos)),
                n=int(len(Yvec)),
                grouped_cv=bool(groups is not None))

Yvec = species_df["lifespan_years"].values.astype(float)
feat_cols = [c for c in species_df.columns if c not in ("species","lifespan_years")]
cpg_cols  = ["gc","cpg_oe"]
kmer_cols = [c for c in feat_cols if c.startswith("kmer_")]

abl_table = pd.DataFrame([
    evaluate_model_X(species_df[cpg_cols],  Yvec, Ridge(alpha=1.0), "CpG+GC | Ridge",  groups=groups),
    evaluate_model_X(species_df[kmer_cols], Yvec, Ridge(alpha=1.0), "k-mers | Ridge",  groups=groups),
    evaluate_model_X(species_df[feat_cols], Yvec, Ridge(alpha=1.0), "All | Ridge",     groups=groups),
])
display(abl_table)
abl_table.to_csv(REPORTS/"baseline_ablations.csv", index=False)

"""## 7) Robustness & ablations

"""

# ╔══════════════════════════════════════════════════════════════════════╗
# ║ 7) MIL deep model — CNN encoder + mean/attention pooling             ║
# ╚══════════════════════════════════════════════════════════════════════╝
device = "cuda" if (CFG["use_gpu"] and torch.cuda.is_available()) else "cpu"

class PromEncoder(nn.Module):
    def __init__(self, filters=CFG["conv_filters"], k=CFG["conv_kernel"], emb=128):
        super().__init__()
        self.conv1 = nn.Conv1d(4, filters, k, padding=k//2)
        self.conv2 = nn.Conv1d(filters, filters, k, padding=k//2)
        self.bn1 = nn.BatchNorm1d(filters); self.bn2 = nn.BatchNorm1d(filters)
        self.pool = nn.AdaptiveAvgPool1d(64)
        self.proj = nn.Linear(filters*64, emb); self.act = nn.GELU()
    def forward(self, x):
        x = self.act(self.bn1(self.conv1(x)))
        x = self.act(self.bn2(self.conv2(x)))
        x = self.pool(x).flatten(1)
        return self.proj(x)

class AttnPooling(nn.Module):
    def __init__(self, dim):
        super().__init__()
        self.score = nn.Sequential(nn.Linear(dim, CFG["atten_dim"]), nn.Tanh(), nn.Linear(CFG["atten_dim"],1))
    def forward(self, H):
        a = torch.softmax(self.score(H).squeeze(-1), dim=0)
        z = (a.unsqueeze(-1) * H).sum(0)
        return z, a

class MILRegressor(nn.Module):
    def __init__(self, enc_dim=128):
        super().__init__()
        self.enc = PromEncoder(emb=enc_dim)
        self.mean_head = nn.Linear(enc_dim, 1)
        self.attn = AttnPooling(enc_dim)
        self.attn_head = nn.Linear(enc_dim, 1)
    def forward(self, bag):
        H = self.enc(bag)
        mean_pred = self.mean_head(H.mean(0)).squeeze()
        z, weights = self.attn(H)
        attn_pred = self.attn_head(z).squeeze()
        return mean_pred, attn_pred, weights

# Build species rows & maps
species_rows = [(r.species, int(r.row_start), int(r.row_end)) for _, r in meta.iterrows()]
lifespan_map = {r.species: float(r.lifespan_years) for _, r in meta.iterrows()}
species_list = [s for s,_,_ in species_rows]

# Optional clade-aware split if taxonomy present
groups_mil = None
tax_path = DATA_DIR / "taxonomy.csv"
if tax_path.exists():
    tax = pd.read_csv(tax_path)
    fam = tax["family"] if "family" in tax.columns else pd.Series(index=tax.index, dtype=object)
    ord_ = tax["order"]  if "order"  in tax.columns else pd.Series(index=tax.index, dtype=object)
    fam_or_order = fam.fillna(ord_)
    gmap = dict(zip(tax["species"].astype(str), fam_or_order.astype(str)))
    groups_mil = np.array([gmap.get(s, s) for s in species_list])

rng = np.random.default_rng(CFG["rng_seed"])
idx_all = np.arange(len(species_list))
if groups_mil is None:
    rng.shuffle(idx_all)
    n = len(idx_all); n_test = int(n*CFG["test_split"]); n_val = int(n*CFG["val_split"])
    te, va, tr = idx_all[:n_test], idx_all[n_test:n_test+n_val], idx_all[n_test+n_val:]
else:
    uniq = np.unique(groups_mil); rng.shuffle(uniq)
    def take_frac(frac, pool): need = max(1, int(len(pool)*frac + 0.5)); return set(pool[:need])
    test_groups = take_frac(CFG["test_split"], uniq)
    rem = [g for g in uniq if g not in test_groups]
    val_groups = take_frac(CFG["val_split"]/(1-CFG["test_split"]+1e-9), rem) if rem else set()
    te = np.array([i for i,g in enumerate(groups_mil) if g in test_groups])
    va = np.array([i for i,g in enumerate(groups_mil) if g in val_groups and i not in set(te)])
    tr = np.array([i for i in range(len(species_list)) if i not in set(te)|set(va)])
splits = dict(train=tr, val=va, test=te)
console.print({"MIL_splits": {k:int(len(v)) for k,v in splits.items()}, "grouped": bool(groups_mil is not None)})

class SpeciesBags(torch.utils.data.Dataset):
    def __init__(self, which): self.which = which
    def __len__(self): return len(splits[self.which])
    def __getitem__(self, i):
        s = species_list[splits[self.which][i]]
        a,b = [(a,b) for ss,a,b in species_rows if ss==s][0]
        rows = np.arange(a,b)
        if len(rows) > CFG["bag_size"]:
            rows = np.random.choice(rows, CFG["bag_size"], replace=False)
        bag = torch.tensor(X[rows], dtype=torch.float32)     # [n,4,1000]
        y = torch.tensor(lifespan_map[s], dtype=torch.float32)
        return bag, y, s

dl = {
    "train": torch.utils.data.DataLoader(SpeciesBags("train"), batch_size=1, shuffle=True),
    "val":   torch.utils.data.DataLoader(SpeciesBags("val"),   batch_size=1, shuffle=False),
    "test":  torch.utils.data.DataLoader(SpeciesBags("test"),  batch_size=1, shuffle=False),
}

model = MILRegressor().to(device)
opt   = torch.optim.AdamW(model.parameters(), lr=CFG["lr"])
lossF = nn.HuberLoss(delta=10.0)

best = {"val": 1e9, "state": None}; patience = CFG["patience"]
for epoch in range(1, CFG["epochs"]+1):
    model.train(); tr_loss = 0.0
    for bag, y, _ in dl["train"]:
        bag = bag.squeeze(0).to(device)         # [m,4,1000]
        y   = y.to(device).view(1)              # <-- (1,) to match pred
        opt.zero_grad()
        m, a, _ = model(bag)                    # scalars (0-d)
        pred = (0.5*m + 0.5*a).view(1)          # <-- make (1,) like y
        loss = lossF(pred, y)                   # no broadcast warning
        loss.backward(); opt.step()
        tr_loss += loss.item()
    model.eval(); val_mae = []
    with torch.no_grad():
        for bag, y, _ in dl["val"]:
            bag = bag.squeeze(0).to(device)
            y   = y.to(device).view(1)
            m, a, _ = model(bag)
            pred = (0.5*m + 0.5*a).view(1)
            val_mae.append(abs((pred - y).item()))
    val_mae = float(np.mean(val_mae)) if val_mae else float("inf")
    console.print(f"epoch {epoch:02d}  train_loss={tr_loss/max(1,len(dl['train'])):.3f}  val_MAE={val_mae:.3f}")
    if val_mae < best["val"] - 1e-6:
        best.update(val=val_mae, state=model.state_dict()); patience = CFG["patience"]
    else:
        patience -= 1
        if patience == 0: break

if best["state"] is not None:
    model.load_state_dict(best["state"])

"""## 8) Publication-grade plots & tables (exported to `/reports`)

"""

# ╔══════════════════════════════════════════════════════════════════════╗
# ║ 8) Evaluation with bootstrap CIs + Acceptance gate                   ║
# ╚══════════════════════════════════════════════════════════════════════╝
def boot_ci(vals, reps=CFG["n_boot"]):
    rng=np.random.default_rng(CFG["rng_seed"]); vals=np.array(vals,dtype=float); n=len(vals)
    means=[np.mean(vals[rng.integers(0,n,size=n)]) for _ in range(reps)]
    lo,hi=np.percentile(means,[2.5,97.5]); return float(lo), float(hi)

def eval_dl(which="test"):
    model.eval(); y_true, y_pred, attn_records = [], [], []
    with torch.no_grad():
        for bag,y,s in dl[which]:
            bag,y = bag.squeeze(0).to(device), float(y.item())
            m,a,w = model(bag); pred = 0.5*float(m.item()) + 0.5*float(a.item())
            y_true.append(y); y_pred.append(pred)
            attn_records.append({"species": s[0], "weights": w.detach().cpu().numpy()})
    y_true, y_pred = np.array(y_true), np.array(y_pred)
    mae = mean_absolute_error(y_true,y_pred); rmse=safe_rmse(y_true,y_pred)
    r2 = r2_score(y_true,y_pred); rho = spearman_stat(y_true,y_pred)
    return dict(MAE=mae, RMSE=rmse, R2=r2, rho=rho), y_true, y_pred, attn_records

test_res, y_t, y_p, attn_rec = eval_dl("test")
err = np.abs(y_t - y_p); mae_lo, mae_hi = boot_ci(err)

# CIs for all metrics (paired bootstrap)
all_cis = metric_bootstrap(y_t, y_p, reps=CFG["n_boot"], seed=CFG["rng_seed"])

naive = float(np.mean(y_t)); naive_mae = float(np.mean(np.abs(y_t - naive)))

console.rule("[bold]Test metrics")
console.print({**test_res, "MAE_CI": (mae_lo, mae_hi), "Naive_MAE": naive_mae, **all_cis})

ACCEPT = (test_res["MAE"] + 1e-9 < naive_mae) and (test_res["R2"] > 0)
console.print("[bold green][ACCEPTANCE] MIL beats naive and R2>0 — proceed[/]" if ACCEPT
              else "[bold yellow][NOTE] MIL did not beat naive or R2<=0 — treat as exploratory[/]")

plt.figure(figsize=(6,6))
plt.scatter(y_t, y_p, alpha=0.7)
mn, mx = float(min(y_t.min(), y_p.min())), float(max(y_t.max(), y_p.max()))
plt.plot([mn,mx],[mn,mx],'k--',lw=1)
plt.xlabel("True lifespan (years)"); plt.ylabel("Predicted")
plt.title(f"MIL — Pred vs True (MAE={test_res['MAE']:.2f}, R2={test_res['R2']:.2f})")
plt.tight_layout(); plt.savefig(REPORTS/"mil_pred_vs_true.png", dpi=200); plt.show()

"""## 9) Run manifest & tiny smoke test

"""

# ╔══════════════════════════════════════════════════════════════════════╗
# ║ 9) Robustness & ablations                                            ║
# ╚══════════════════════════════════════════════════════════════════════╝
def ablate_pooling():
    model.eval()
    y_true, y_mean, y_attn = [], [], []
    with torch.no_grad():
        for bag,y,_ in dl["test"]:
            bag,y = bag.squeeze(0).to(device), y.item()
            mean_pred, attn_pred, _ = model(bag)
            y_true.append(y); y_mean.append(mean_pred.item()); y_attn.append(attn_pred.item())
    def metrics(t,p):
        return dict(MAE=mean_absolute_error(t,p), R2=r2_score(t,p), rho=spearman_stat(t,p))
    return metrics(y_true, y_mean), metrics(y_true, y_attn)

m_mean, m_attn = ablate_pooling()
console.print({"mean_pool": m_mean, "attn_pool": m_attn})

def bag_sensitivity(bag_sizes=(64,128,256)):
    out = []
    for bs in bag_sizes:
        CFG["bag_size"]=bs
        m = MILRegressor().to(device); m.load_state_dict(model.state_dict())
        ys, ps = [], []
        with torch.no_grad():
            for bag,y,_ in dl["test"]:
                full = bag.squeeze(0)
                rows = torch.randperm(full.shape[0])[:min(bs, full.shape[0])]
                bag_bs = full[rows].to(device)
                mean_pred, attn_pred, _ = m(bag_bs)
                ps.append(0.5*mean_pred.item()+0.5*attn_pred.item()); ys.append(y.item())
        out.append({"bag_size": bs, "MAE": mean_absolute_error(ys, ps)})
    return pd.DataFrame(out)

bag_df = bag_sensitivity()
display(bag_df)
bag_df.to_csv(REPORTS/"robustness_bag_size.csv", index=False)

# ╔══════════════════════════════════════════════════════════════════════╗
# ║ 10) Export attention: top-N promoters per test species               ║
# ╚══════════════════════════════════════════════════════════════════════╝
TOP_N = 10
attn_rows = []
with torch.no_grad():
    for bag, y, s in dl["test"]:
        s = s[0]
        a,b = [(a,b) for ss,a,b in species_rows if ss==s][0]
        rows = np.arange(a,b)
        if len(rows) > CFG["bag_size"]:
            rows = np.random.choice(rows, CFG["bag_size"], replace=False)
        bag = torch.tensor(X[rows], dtype=torch.float32).to(device)
        _, _, weights = model(bag)
        w = weights.detach().cpu().numpy()
        top_idx = np.argsort(-w)[:min(TOP_N, len(w))]
        for rank, i_local in enumerate(top_idx, 1):
            attn_rows.append({
                "species": s,
                "rank": rank,
                "global_row": int(rows[i_local]),
                "weight": float(w[i_local])
            })

attn_df = pd.DataFrame(attn_rows).sort_values(["species","rank"])
attn_df.to_csv(REPORTS/"attn_top_promoters.csv", index=False)
display(attn_df.head(20))
console.print("[green]Exported attention tops →", REPORTS/"attn_top_promoters.csv")

# ╔══════════════════════════════════════════════════════════════════════╗
# ║ 11) Publication-grade plots & results export                         ║
# ╚══════════════════════════════════════════════════════════════════════╝
# Residuals
resid = y_t - y_p
fig, ax = plt.subplots(1,2, figsize=(12,5))
sns.histplot(resid, kde=True, ax=ax[0]); ax[0].set_title("Residuals")
sns.scatterplot(x=y_p, y=resid, ax=ax[1]); ax[1].axhline(0,color="k",ls="--",lw=1)
ax[1].set_xlabel("Predicted"); ax[1].set_ylabel("Residual")
plt.tight_layout(); plt.savefig(REPORTS/"mil_residuals.png", dpi=200); plt.show()

summary = {
    "baselines": baseline_table.to_dict(orient="records"),
    "mil_test": test_res,
    "mil_test_CIs": {
        "MAE_CI": [float(np.round(x,6)) for x in metric_bootstrap(y_t, y_p, reps=CFG["n_boot"], seed=CFG["rng_seed"])["MAE_CI"]],
        "RMSE_CI": [float(np.round(x,6)) for x in metric_bootstrap(y_t, y_p, reps=CFG["n_boot"], seed=CFG["rng_seed"])["RMSE_CI"]],
        "R2_CI": [float(np.round(x,6)) for x in metric_bootstrap(y_t, y_p, reps=CFG["n_boot"], seed=CFG["rng_seed"])["R2_CI"]],
        "rho_CI": [float(np.round(x,6)) for x in metric_bootstrap(y_t, y_p, reps=CFG["n_boot"], seed=CFG["rng_seed"])["rho_CI"]],
    },
    "naive_MAE": float(np.mean(np.abs(y_t - float(np.mean(y_t))))),
    "ablation_pooling": {"mean_pool": m_mean, "attn_pool": m_attn},
}
import json
json.dump(summary, open(REPORTS/"results_summary.json","w"))
console.print("[green]Exported: eda_overview.png, baselines_pred_vs_true.png, mil_pred_vs_true.png, mil_residuals.png, robustness_bag_size.csv, results_summary.json")

# ╔══════════════════════════════════════════════════════════════════════╗
# ║ 12) Run manifest, smoke test, data dictionary & changelog            ║
# ╚══════════════════════════════════════════════════════════════════════╝
manifest = dict(
    run_id=run_id,
    timestamp=datetime.utcnow().isoformat()+"Z",
    cfg=CFG,
    env=dict(
        python=sys.version,
        numpy=np.__version__,
        pandas=pd.__version__,
        torch=torch.__version__,
        sklearn=sklearn.__version__,
    ),
    paths=dict(data=str(DATA_DIR), reports=str(REPORTS), artifacts=str(ARTIFACTS)),
    mode=MODE
)
with open(ARTIFACTS/"run_manifest.json","w") as f:
    json.dump(manifest, f, indent=2)
console.print("[bold green]Run manifest written:", ARTIFACTS/"run_manifest.json")

# Smoke test on a handful of test species
def smoke_test(n=5):
    model.eval()
    ys, ps = [], []
    with torch.no_grad():
        c = 0
        for bag,y,_ in dl["test"]:
            bag = bag.squeeze(0)[:min(CFG["bag_size"], bag.shape[0])].to(device)
            m,a,_ = model(bag)
            ps.append(0.5*float(m.item())+0.5*float(a.item())); ys.append(float(y.item()))
            c += 1
            if c >= n: break
    return dict(MAE=mean_absolute_error(ys, ps), n=len(ys))
console.print("[cyan]Smoke test:", smoke_test(5))

# Data dictionary & changelog
cpg_cols  = ["gc","cpg_oe"]
kmer_cols = [c for c in species_df.columns if c.startswith("kmer_")]
data_dict = {
    "species_matrix.csv": {
        "columns": {c: str(species_df[c].dtype) for c in species_df.columns},
        "n_species": int(species_df.shape[0]),
        "n_features": int(species_df.shape[1]-2),
        "feature_groups": {"cpg_cols": cpg_cols, "kmer_cols_count": len(kmer_cols)}
    },
    "promoter_index.tsv": "expected columns: row_start,row_end,species,assembly",
    "labels": str(LBL_PATH) if 'LBL_PATH' in globals() and LBL_PATH else None,
    "taxonomy": str(TAX_PATH) if 'TAX_PATH' in globals() and TAX_PATH else None,
    "X_promoters_shape": list(X.shape),
    "MODE": MODE
}
json.dump(data_dict, open(REPORTS/"data_dictionary.json","w"), indent=2)

with open(ARTIFACTS/"changelog.txt","a") as f:
    f.write(f"[{datetime.utcnow().isoformat()}Z] Initial full pipeline; clade-aware splits; metric CIs; baseline ablations; attention export; data dictionary.\n")

console.print("[green]Exported data_dictionary.json and updated changelog.txt")